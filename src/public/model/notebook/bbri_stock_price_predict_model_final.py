# -*- coding: utf-8 -*-
"""BBRI Stock Price Predict Model final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mu4wRaY010whj2s0_DGc_3ZJ228duJ5h

# Install and Import Library
"""

!pip install tensorflowjs

# Commented out IPython magic to ensure Python compatibility.
import datetime
import json
import datetime
import time
import requests
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt


from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_percentage_error
# %matplotlib inline

"""# Data Preparation

## Data Collection
"""

start_date_str = '2022-01-01'
start_date_dt = datetime.datetime.strptime(start_date_str, '%Y-%m-%d')
start_date = int(start_date_dt.timestamp())

end_date = int(time.time()); # hari ini

YAHOO_FINANCE_URL = f"https://query1.finance.yahoo.com/v8/finance/chart/BBRI.JK?events=capitalGain%7Cdiv%7Csplit&formatted=true&includeAdjustedClose=true&interval=1d&period1={start_date}&period2={end_date}&symbol=BBRI.JK&userYfid=true&lang=en-US&region=US"

def process_stock_data(data):
    try:
        # Navigasi ke struktur data yang diinginkan
        result = data['chart']['result'][0]

        # Ekstrak data timestamp dan ubah menjadi format tanggal
        timestamps = result['timestamp']
        dates = [datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d') for ts in timestamps]

        # Ekstrak data harga dan volume
        quote = result['indicators']['quote'][0]
        opens = quote['open']
        highs = quote['high']
        lows = quote['low']
        closes = quote['close']
        volumes = quote['volume']

        # Ekstrak adjusted close jika tersedia
        if 'adjclose' in result:
            adjcloses = result['adjclose']
        elif 'adjclose' in result['indicators']:
            adjcloses = result['indicators']['adjclose'][0]['adjclose']
        else:
            adjcloses = closes  # Fallback jika tidak ada adjclose

        # Buat DataFrame
        df = pd.DataFrame({
            'Date': dates,
            'Open': opens,
            'High': highs,
            'Low': lows,
            'Close': closes,
            'Volume': volumes,
            'AdjustedClose': adjcloses
        })

        # Simpan ke CSV dengan nama file yang lebih spesifik
        stock_symbol = result['meta']['symbol'] if 'symbol' in result['meta'] else 'BBRI.JK'
        csv_filename = f"{stock_symbol}_data.csv"
        df.to_csv(csv_filename, index=False)
        print(f"Data untuk {stock_symbol} berhasil disimpan ke {csv_filename}")

        # Tampilkan informasi ringkas
        print(f"Total data: {len(df)} records")
        print(f"Rentang waktu: {df['Date'].min()} sampai {df['Date'].max()}")

        # Tampilkan beberapa baris pertama dan terakhir untuk verifikasi
        print("\nBeberapa data awal:")
        display(df.head())

        print("\nBeberapa data akhir:")
        display(df.tail())

        return df

    except KeyError as e:
        print(f"Error: Kunci tidak ditemukan - {e}")
        print("Struktur data JSON mungkin berbeda dari yang diharapkan.")
        # Tampilkan struktur data untuk debugging
        print("Struktur data tingkat atas:", list(data.keys()))
        if 'chart' in data:
            print("Struktur chart:", list(data['chart'].keys()))
            if 'result' in data['chart'] and len(data['chart']['result']) > 0:
                print("Struktur result[0]:", list(data['chart']['result'][0].keys()))
    except Exception as e:
        print(f"Error: {e}")

def get_bbri_stock_data():
    """
    Fungsi khusus untuk mendapatkan data saham BBRI.JK dari Yahoo Finance
    """
    try:
        print(f"Mengambil data saham BBRI.JK dari Yahoo Finance...")

        # Tambahkan user-agent header untuk menghindari penolakan permintaan
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }

        response = requests.get(YAHOO_FINANCE_URL, headers=headers)

        # Periksa status respons
        if response.status_code != 200:
            print(f"Error: Mendapatkan kode status {response.status_code}")
            print(f"Response: {response.text}")
            return None

        # Parse JSON response
        data = response.json()

        # Proses data
        return process_stock_data(data)

    except Exception as e:
        print(f"Error mendapatkan data dari Yahoo Finance API: {e}")
        return None

# Jalankan fungsi untuk mendapatkan dan memproses data
bbri_data = get_bbri_stock_data()

# Menawarkan opsi untuk mendownload file CSV
try:
    from google.colab import files
    if bbri_data is not None:
        print("Anda dapat mendownload file CSV dengan mengklik link di atas.")
except ImportError:
    print("Tampaknya Anda tidak menjalankan kode di Google Colab.")
    print("File CSV tersimpan di direktori lokal Anda.")

"""## Data Selection"""

file_path = "/content/BBRI.JK_data.csv"

# Load dataset
df = pd.read_csv(file_path, index_col=0)

# Preview
df.head()

"""### Plot Data"""

df['Close'].plot(figsize=(10, 7))
plt.title("BBRI Stock Price", fontsize=17)
plt.ylabel('Price', fontsize=14)
plt.xlabel('Time', fontsize=14)
plt.grid(which="major", color='k', linestyle='-.', linewidth=0.5)
plt.show()

"""## Data Cleaning"""

# Handling missing values (if any)
df.dropna(inplace=True)
print(df.columns)

df.head()

# Detect and cap outliers in numerical columns
num_cols = ["Open", "High", "Low", "Close", "Volume", "AdjustedClose"]
for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    upper_bound = Q3 + 1.5 * IQR
    lower_bound = Q1 - 1.5 * IQR
    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])
    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])

# Save cleaned dataset
cleaned_file_path = "stock_price_cleaned.csv"  # Ganti dengan path untuk menyimpan di Google Colab
df.to_csv(cleaned_file_path, index=False)

print("Dataset cleaned and saved successfully!")

# Display first few rows of cleaned dataset
df.head()

df.columns

"""## Split Validation data using Walk-Forward Validation

### Load Cleaned Dataset
"""

# Load cleaned dataset
df = pd.read_csv("stock_price_cleaned.csv")

# Pilih fitur dan target
X = df.drop(columns=["Close"])  # Semua kecuali harga penutupan
y = df["Close"]  # Target yang diprediksi

"""### Split"""

# Walk-Forward Validation
train_size = int(len(X) * 0.8)  # 80% training, 20% testing
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

"""## Data Transformation"""

# Konversi data ke format numpy array
X_train, X_test = np.array(X_train, dtype=np.float32), np.array(X_test, dtype=np.float32)
y_train, y_test = np.array(y_train, dtype=np.float32), np.array(y_test, dtype=np.float32)

"""# Model

## Build Model using Linier Regression with Least Square Method
"""

# Membangun model Least Square (Linear Regression)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(1, input_shape=(X_train.shape[1],))  # Linear Regression
])

"""### Compile Model"""

# Compile model
model.compile(optimizer="adam", loss="mse", metrics=["mae", "mape"])

"""## Model Training"""

from tensorflow.keras.callbacks import Callback

class StopOnMAPEThreshold(Callback):
    def __init__(self, threshold=10.0, monitor='mape'):
        super().__init__()
        self.threshold = threshold
        self.monitor = monitor

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        current = logs.get(self.monitor)
        if current is None:
            print(f"[WARNING] Metrik '{self.monitor}' tidak ditemukan di logs.")
            return
        if current < self.threshold:
            print(f"\nâœ… MAPE {current:.4f}% sudah < threshold {self.threshold}%. Stop training.")
            self.model.stop_training = True

# Callback
callbacks = [
    StopOnMAPEThreshold(threshold=10.0),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
]

# Training model
# model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)
model.fit(
    X_train, y_train,
    epochs=1000,  # cukup besar, nanti diberhentikan otomatis
    batch_size=16,
    callbacks=callbacks,
    verbose=1
)

"""## Model Evaluation

### MSE (Mean Squared Error)
"""

# Evaluasi model
loss = model.evaluate(X_test, y_test)
print(f"Model Loss: {loss}")

"""### MAPE (Mean Absolute Percentage Error)"""

# Prediksi nilai pada test set
y_pred = model.predict(X_test).flatten()

# Hitung MAPE
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"Mean Absolute Percentage Error (MAPE): {mape:.4f}")

"""## Model Summary"""

model.summary()

"""## Save & Convert Model

### Save to H5 and Keras
"""

model.save("stock_price_model.h5")
model.save("stock_price_model.keras")
print("Model h5 and keras saved successfully!")

""" ### Export to SavedModel"""

model.export("saved_model")

"""### Convert Saved Model into JSON Format"""

!tensorflowjs_converter --input_format=tf_saved_model saved_model tfjs_model

"""### Archive Model"""

# Zip folder tfjs_model untuk diunduh
!zip -r tfjs_model.zip tfjs_model

"""# Download Cleaned Dataset, Checkpoint, & tfjs Model"""

from google.colab import files

files.download('/content/BBRI.JK_data.csv')
files.download('/content/stock_price_cleaned.csv')
files.download('/content/stock_price_model.h5')
files.download('/content/stock_price_model.keras')
files.download('/content/tfjs_model.zip')